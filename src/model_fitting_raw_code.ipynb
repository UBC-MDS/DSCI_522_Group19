{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "34c77f90-6f9b-49e0-a67e-c684fa30d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    average_precision_score, \n",
    "    auc\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4e67f4c5-f3da-4eb3-9aab-64bd2b268a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_df = pd.read_csv(\"../data/winequality-white.csv\", sep=\";\")\n",
    "red_df = pd.read_csv(\"../data/winequality-red.csv\", sep=\";\")\n",
    "\n",
    "red_df['type']='red wine'\n",
    "white_df['type']='white wine'\n",
    "wine = pd.concat([red_df,white_df]).reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "348c881b-1424-4381-9b54-18e8211b8dec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddaa3243-1b87-4533-9a9f-9b2225e3a5bf",
   "metadata": {},
   "source": [
    "We combined both csv files together and created a \"type\" column to see whether the type of the wine will affect the judgement of the quality. Because sometimes, human's perception of wine type may affect the independent scoring on the wine quality, so that's why we added a binary feature to account for this factor. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "9018bcf2-4320-459f-8f4b-579a11c851c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "42a2dc65-6a14-438c-949c-caefdfb9ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(wine, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "474d866f-ec50-4ce2-b0f1-6c46543718d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"quality\"])\n",
    "X_test = test_df.drop(columns=[\"quality\"])\n",
    "\n",
    "y_train = train_df[\"quality\"]\n",
    "y_test = test_df[\"quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "4029b7f7-b303-4c32-adbb-33f698248a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = X_train.select_dtypes(include=[np.number]).columns.values.tolist()\n",
    "binary_feats = [\"type\"]\n",
    "\n",
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "binary_transformer = make_pipeline(OneHotEncoder(drop=\"if_binary\", dtype=int))\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_feats),\n",
    "    (binary_transformer, binary_feats)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "274d8755-91d4-4815-a5f9-10db13adf20c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79e4d9a8-61f1-4292-85b3-76a361a2460f",
   "metadata": {},
   "source": [
    "In our data file, we only have numerical features originally; however we need to scale those number before we feed them in the model. And we engineered a binary feature (\"type\"), we used `OneHotEncoder` with `drop=\"if_binary\"` argument to form the transformer. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c89bba31-ec7a-4c0c-b6ef-740683c1fe65",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "badf7f5b-f0fb-431f-b7d2-78d9070f6011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.552156</td>\n",
       "      <td>-0.537847</td>\n",
       "      <td>-0.616843</td>\n",
       "      <td>-0.849603</td>\n",
       "      <td>-0.256654</td>\n",
       "      <td>-0.599698</td>\n",
       "      <td>-0.688718</td>\n",
       "      <td>-1.550251</td>\n",
       "      <td>0.637496</td>\n",
       "      <td>0.602356</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.551023</td>\n",
       "      <td>-0.903607</td>\n",
       "      <td>-0.274431</td>\n",
       "      <td>-0.849603</td>\n",
       "      <td>-0.285082</td>\n",
       "      <td>-0.487984</td>\n",
       "      <td>-0.460217</td>\n",
       "      <td>-1.427678</td>\n",
       "      <td>-0.236615</td>\n",
       "      <td>-0.134424</td>\n",
       "      <td>1.005574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065059</td>\n",
       "      <td>-0.720727</td>\n",
       "      <td>0.547359</td>\n",
       "      <td>1.949924</td>\n",
       "      <td>-0.398798</td>\n",
       "      <td>0.768801</td>\n",
       "      <td>0.234073</td>\n",
       "      <td>1.692956</td>\n",
       "      <td>0.887242</td>\n",
       "      <td>-0.804224</td>\n",
       "      <td>-1.161136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.165971</td>\n",
       "      <td>-0.598807</td>\n",
       "      <td>0.273429</td>\n",
       "      <td>-0.556020</td>\n",
       "      <td>-0.626230</td>\n",
       "      <td>-0.487984</td>\n",
       "      <td>-0.073524</td>\n",
       "      <td>-1.553564</td>\n",
       "      <td>-0.174178</td>\n",
       "      <td>-1.005164</td>\n",
       "      <td>1.755589</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.011951</td>\n",
       "      <td>-0.598807</td>\n",
       "      <td>-0.137466</td>\n",
       "      <td>-0.807663</td>\n",
       "      <td>-0.228225</td>\n",
       "      <td>-0.208698</td>\n",
       "      <td>0.260438</td>\n",
       "      <td>-0.460348</td>\n",
       "      <td>0.200441</td>\n",
       "      <td>-0.536304</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>-0.319992</td>\n",
       "      <td>0.681350</td>\n",
       "      <td>-0.274431</td>\n",
       "      <td>4.319561</td>\n",
       "      <td>-0.711516</td>\n",
       "      <td>-0.208698</td>\n",
       "      <td>0.102245</td>\n",
       "      <td>2.736480</td>\n",
       "      <td>-0.985853</td>\n",
       "      <td>-0.737244</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>0.758151</td>\n",
       "      <td>-0.476888</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>-0.597961</td>\n",
       "      <td>-0.086080</td>\n",
       "      <td>-1.102412</td>\n",
       "      <td>-0.794180</td>\n",
       "      <td>-0.221828</td>\n",
       "      <td>-2.047274</td>\n",
       "      <td>-0.268384</td>\n",
       "      <td>-0.827796</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>-0.859063</td>\n",
       "      <td>1.534788</td>\n",
       "      <td>-2.123458</td>\n",
       "      <td>-0.702812</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>-1.437555</td>\n",
       "      <td>-1.813644</td>\n",
       "      <td>0.010066</td>\n",
       "      <td>1.886227</td>\n",
       "      <td>0.200476</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>0.604131</td>\n",
       "      <td>-0.720727</td>\n",
       "      <td>-0.274431</td>\n",
       "      <td>1.792647</td>\n",
       "      <td>-0.086080</td>\n",
       "      <td>2.919299</td>\n",
       "      <td>1.420518</td>\n",
       "      <td>1.129784</td>\n",
       "      <td>-0.486361</td>\n",
       "      <td>-0.536304</td>\n",
       "      <td>-0.577791</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>0.296090</td>\n",
       "      <td>-0.842647</td>\n",
       "      <td>-0.137466</td>\n",
       "      <td>1.834587</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>1.243586</td>\n",
       "      <td>1.692961</td>\n",
       "      <td>1.427934</td>\n",
       "      <td>-0.486361</td>\n",
       "      <td>-0.469324</td>\n",
       "      <td>-1.327806</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0         -1.552156         -0.537847    -0.616843       -0.849603  -0.256654   \n",
       "1         -0.551023         -0.903607    -0.274431       -0.849603  -0.285082   \n",
       "2          0.065059         -0.720727     0.547359        1.949924  -0.398798   \n",
       "3         -0.165971         -0.598807     0.273429       -0.556020  -0.626230   \n",
       "4         -0.011951         -0.598807    -0.137466       -0.807663  -0.228225   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "5192      -0.319992          0.681350    -0.274431        4.319561  -0.711516   \n",
       "5193       0.758151         -0.476888     0.067982       -0.597961  -0.086080   \n",
       "5194      -0.859063          1.534788    -2.123458       -0.702812  -0.000793   \n",
       "5195       0.604131         -0.720727    -0.274431        1.792647  -0.086080   \n",
       "5196       0.296090         -0.842647    -0.137466        1.834587  -0.000793   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "0               -0.599698             -0.688718 -1.550251  0.637496   \n",
       "1               -0.487984             -0.460217 -1.427678 -0.236615   \n",
       "2                0.768801              0.234073  1.692956  0.887242   \n",
       "3               -0.487984             -0.073524 -1.553564 -0.174178   \n",
       "4               -0.208698              0.260438 -0.460348  0.200441   \n",
       "...                   ...                   ...       ...       ...   \n",
       "5192            -0.208698              0.102245  2.736480 -0.985853   \n",
       "5193            -1.102412             -0.794180 -0.221828 -2.047274   \n",
       "5194            -1.437555             -1.813644  0.010066  1.886227   \n",
       "5195             2.919299              1.420518  1.129784 -0.486361   \n",
       "5196             1.243586              1.692961  1.427934 -0.486361   \n",
       "\n",
       "      sulphates   alcohol  type  \n",
       "0      0.602356  0.755569   1.0  \n",
       "1     -0.134424  1.005574   1.0  \n",
       "2     -0.804224 -1.161136   1.0  \n",
       "3     -1.005164  1.755589   1.0  \n",
       "4     -0.536304  0.005554   1.0  \n",
       "...         ...       ...   ...  \n",
       "5192  -0.737244  0.088889   1.0  \n",
       "5193  -0.268384 -0.827796   1.0  \n",
       "5194   0.200476  0.755569   0.0  \n",
       "5195  -0.536304 -0.577791   1.0  \n",
       "5196  -0.469324 -1.327806   1.0  \n",
       "\n",
       "[5197 rows x 12 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_name = numeric_feats + binary_feats\n",
    "pd.DataFrame(preprocessor.fit_transform(X_train, y_train), columns = column_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d031f411-f530-4993-9f16-acf76b8c76c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "78eaf113-7a0f-41e3-b8cc-8294be97ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported from DSCI 573 Lecture Notes from UBC\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e82be241-e31f-4d54-9bd6-94d761c78bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported from DSCI 573 Lecture Notes from UBC\n",
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(max_iter=2000),\n",
    "    \"SVC\": SVC(),\n",
    "    \"OneVsRest\":OneVsRestClassifier(LogisticRegression()),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=123)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2435e9c4-bd91-4bf1-9e1b-a8309a328e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVC</th>\n",
       "      <th>OneVsRest</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.010 (+/- 0.002)</td>\n",
       "      <td>0.770 (+/- 0.051)</td>\n",
       "      <td>0.100 (+/- 0.006)</td>\n",
       "      <td>1.501 (+/- 0.023)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.373 (+/- 0.008)</td>\n",
       "      <td>0.006 (+/- 0.000)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <td>-0.542 (+/- 0.034)</td>\n",
       "      <td>-0.587 (+/- 0.016)</td>\n",
       "      <td>-0.648 (+/- 0.006)</td>\n",
       "      <td>-0.395 (+/- 0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <td>-0.536 (+/- 0.009)</td>\n",
       "      <td>-0.542 (+/- 0.007)</td>\n",
       "      <td>-0.642 (+/- 0.005)</td>\n",
       "      <td>-0.056 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <td>-0.736 (+/- 0.023)</td>\n",
       "      <td>-0.766 (+/- 0.010)</td>\n",
       "      <td>-0.805 (+/- 0.004)</td>\n",
       "      <td>-0.628 (+/- 0.021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <td>-0.732 (+/- 0.006)</td>\n",
       "      <td>-0.736 (+/- 0.005)</td>\n",
       "      <td>-0.801 (+/- 0.003)</td>\n",
       "      <td>-0.237 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <td>-0.570 (+/- 0.015)</td>\n",
       "      <td>-0.480 (+/- 0.010)</td>\n",
       "      <td>-0.520 (+/- 0.003)</td>\n",
       "      <td>-0.450 (+/- 0.012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <td>-0.567 (+/- 0.004)</td>\n",
       "      <td>-0.441 (+/- 0.004)</td>\n",
       "      <td>-0.514 (+/- 0.002)</td>\n",
       "      <td>-0.169 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.289 (+/- 0.029)</td>\n",
       "      <td>0.231 (+/- 0.020)</td>\n",
       "      <td>0.150 (+/- 0.006)</td>\n",
       "      <td>0.482 (+/- 0.027)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.298 (+/- 0.007)</td>\n",
       "      <td>0.290 (+/- 0.011)</td>\n",
       "      <td>0.158 (+/- 0.008)</td>\n",
       "      <td>0.926 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <td>-10.156 (+/- 0.445)</td>\n",
       "      <td>-8.436 (+/- 0.152)</td>\n",
       "      <td>-9.027 (+/- 0.057)</td>\n",
       "      <td>-8.122 (+/- 0.406)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape_scorer</th>\n",
       "      <td>-10.093 (+/- 0.095)</td>\n",
       "      <td>-7.712 (+/- 0.066)</td>\n",
       "      <td>-8.917 (+/- 0.035)</td>\n",
       "      <td>-3.041 (+/- 0.049)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Ridge                 SVC  \\\n",
       "fit_time                             0.010 (+/- 0.002)   0.770 (+/- 0.051)   \n",
       "score_time                           0.005 (+/- 0.001)   0.373 (+/- 0.008)   \n",
       "test_neg_mean_squared_error         -0.542 (+/- 0.034)  -0.587 (+/- 0.016)   \n",
       "train_neg_mean_squared_error        -0.536 (+/- 0.009)  -0.542 (+/- 0.007)   \n",
       "test_neg_root_mean_squared_error    -0.736 (+/- 0.023)  -0.766 (+/- 0.010)   \n",
       "train_neg_root_mean_squared_error   -0.732 (+/- 0.006)  -0.736 (+/- 0.005)   \n",
       "test_neg_mean_absolute_error        -0.570 (+/- 0.015)  -0.480 (+/- 0.010)   \n",
       "train_neg_mean_absolute_error       -0.567 (+/- 0.004)  -0.441 (+/- 0.004)   \n",
       "test_r2                              0.289 (+/- 0.029)   0.231 (+/- 0.020)   \n",
       "train_r2                             0.298 (+/- 0.007)   0.290 (+/- 0.011)   \n",
       "test_mape_scorer                   -10.156 (+/- 0.445)  -8.436 (+/- 0.152)   \n",
       "train_mape_scorer                  -10.093 (+/- 0.095)  -7.712 (+/- 0.066)   \n",
       "\n",
       "                                            OneVsRest       Random Forest  \n",
       "fit_time                            0.100 (+/- 0.006)   1.501 (+/- 0.023)  \n",
       "score_time                          0.006 (+/- 0.000)   0.021 (+/- 0.000)  \n",
       "test_neg_mean_squared_error        -0.648 (+/- 0.006)  -0.395 (+/- 0.027)  \n",
       "train_neg_mean_squared_error       -0.642 (+/- 0.005)  -0.056 (+/- 0.002)  \n",
       "test_neg_root_mean_squared_error   -0.805 (+/- 0.004)  -0.628 (+/- 0.021)  \n",
       "train_neg_root_mean_squared_error  -0.801 (+/- 0.003)  -0.237 (+/- 0.003)  \n",
       "test_neg_mean_absolute_error       -0.520 (+/- 0.003)  -0.450 (+/- 0.012)  \n",
       "train_neg_mean_absolute_error      -0.514 (+/- 0.002)  -0.169 (+/- 0.002)  \n",
       "test_r2                             0.150 (+/- 0.006)   0.482 (+/- 0.027)  \n",
       "train_r2                            0.158 (+/- 0.008)   0.926 (+/- 0.002)  \n",
       "test_mape_scorer                   -9.027 (+/- 0.057)  -8.122 (+/- 0.406)  \n",
       "train_mape_scorer                  -8.917 (+/- 0.035)  -3.041 (+/- 0.049)  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_comb={}\n",
    "for keys in models.keys():\n",
    "    pipe_comb = make_pipeline(preprocessor, models[keys])\n",
    "    results_comb[keys]=mean_std_cross_val_scores(\n",
    "        pipe_comb, X_train, y_train, return_train_score=True, scoring=score_types_reg\n",
    "    )\n",
    "pd.DataFrame(results_comb)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9519454a-f95a-404f-94b6-c619c2273849",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f30622a-0747-4dae-b8e2-f376f8b6c3f0",
   "metadata": {},
   "source": [
    "After comparing different regression models by using various matrix, we found the better model is Random Forest, because we got highest cross-validation score. However, we figured out that we may encounter some overfitting issue with Random Forest model as the difference between train score and validation score is quite wide. So, we further conduct feature selections and hyper-parameter optimization as follows. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "813897a4-22de-4c3c-9c08-b8dcc03e91cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "09fdca02-1215-47f1-a028-6324cf4f71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(RandomForestRegressor(random_state=123), n_features_to_select=10)\n",
    "\n",
    "pipe_rf_rfe = make_pipeline(preprocessor, rfe, RandomForestRegressor(random_state=123))\n",
    "\n",
    "results_comb['Random Forest_rfe'] = mean_std_cross_val_scores(pipe_rf_rfe, X_train, y_train, return_train_score=True, scoring=score_types_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ac373d52-ae9f-440c-925f-66da7d0df55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ridge</th>\n",
       "      <th>SVC</th>\n",
       "      <th>OneVsRest</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Random Forest_rfe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.010 (+/- 0.002)</td>\n",
       "      <td>0.770 (+/- 0.051)</td>\n",
       "      <td>0.100 (+/- 0.006)</td>\n",
       "      <td>1.501 (+/- 0.023)</td>\n",
       "      <td>5.762 (+/- 0.081)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.005 (+/- 0.001)</td>\n",
       "      <td>0.373 (+/- 0.008)</td>\n",
       "      <td>0.006 (+/- 0.000)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <td>-0.542 (+/- 0.034)</td>\n",
       "      <td>-0.587 (+/- 0.016)</td>\n",
       "      <td>-0.648 (+/- 0.006)</td>\n",
       "      <td>-0.395 (+/- 0.027)</td>\n",
       "      <td>-0.395 (+/- 0.031)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_squared_error</th>\n",
       "      <td>-0.536 (+/- 0.009)</td>\n",
       "      <td>-0.542 (+/- 0.007)</td>\n",
       "      <td>-0.642 (+/- 0.005)</td>\n",
       "      <td>-0.056 (+/- 0.002)</td>\n",
       "      <td>-0.056 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <td>-0.736 (+/- 0.023)</td>\n",
       "      <td>-0.766 (+/- 0.010)</td>\n",
       "      <td>-0.805 (+/- 0.004)</td>\n",
       "      <td>-0.628 (+/- 0.021)</td>\n",
       "      <td>-0.628 (+/- 0.025)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_root_mean_squared_error</th>\n",
       "      <td>-0.732 (+/- 0.006)</td>\n",
       "      <td>-0.736 (+/- 0.005)</td>\n",
       "      <td>-0.801 (+/- 0.003)</td>\n",
       "      <td>-0.237 (+/- 0.003)</td>\n",
       "      <td>-0.238 (+/- 0.003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <td>-0.570 (+/- 0.015)</td>\n",
       "      <td>-0.480 (+/- 0.010)</td>\n",
       "      <td>-0.520 (+/- 0.003)</td>\n",
       "      <td>-0.450 (+/- 0.012)</td>\n",
       "      <td>-0.451 (+/- 0.015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_neg_mean_absolute_error</th>\n",
       "      <td>-0.567 (+/- 0.004)</td>\n",
       "      <td>-0.441 (+/- 0.004)</td>\n",
       "      <td>-0.514 (+/- 0.002)</td>\n",
       "      <td>-0.169 (+/- 0.002)</td>\n",
       "      <td>-0.169 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_r2</th>\n",
       "      <td>0.289 (+/- 0.029)</td>\n",
       "      <td>0.231 (+/- 0.020)</td>\n",
       "      <td>0.150 (+/- 0.006)</td>\n",
       "      <td>0.482 (+/- 0.027)</td>\n",
       "      <td>0.481 (+/- 0.032)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_r2</th>\n",
       "      <td>0.298 (+/- 0.007)</td>\n",
       "      <td>0.290 (+/- 0.011)</td>\n",
       "      <td>0.158 (+/- 0.008)</td>\n",
       "      <td>0.926 (+/- 0.002)</td>\n",
       "      <td>0.926 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_mape_scorer</th>\n",
       "      <td>-10.156 (+/- 0.445)</td>\n",
       "      <td>-8.436 (+/- 0.152)</td>\n",
       "      <td>-9.027 (+/- 0.057)</td>\n",
       "      <td>-8.122 (+/- 0.406)</td>\n",
       "      <td>-8.125 (+/- 0.447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_mape_scorer</th>\n",
       "      <td>-10.093 (+/- 0.095)</td>\n",
       "      <td>-7.712 (+/- 0.066)</td>\n",
       "      <td>-8.917 (+/- 0.035)</td>\n",
       "      <td>-3.041 (+/- 0.049)</td>\n",
       "      <td>-3.048 (+/- 0.044)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Ridge                 SVC  \\\n",
       "fit_time                             0.010 (+/- 0.002)   0.770 (+/- 0.051)   \n",
       "score_time                           0.005 (+/- 0.001)   0.373 (+/- 0.008)   \n",
       "test_neg_mean_squared_error         -0.542 (+/- 0.034)  -0.587 (+/- 0.016)   \n",
       "train_neg_mean_squared_error        -0.536 (+/- 0.009)  -0.542 (+/- 0.007)   \n",
       "test_neg_root_mean_squared_error    -0.736 (+/- 0.023)  -0.766 (+/- 0.010)   \n",
       "train_neg_root_mean_squared_error   -0.732 (+/- 0.006)  -0.736 (+/- 0.005)   \n",
       "test_neg_mean_absolute_error        -0.570 (+/- 0.015)  -0.480 (+/- 0.010)   \n",
       "train_neg_mean_absolute_error       -0.567 (+/- 0.004)  -0.441 (+/- 0.004)   \n",
       "test_r2                              0.289 (+/- 0.029)   0.231 (+/- 0.020)   \n",
       "train_r2                             0.298 (+/- 0.007)   0.290 (+/- 0.011)   \n",
       "test_mape_scorer                   -10.156 (+/- 0.445)  -8.436 (+/- 0.152)   \n",
       "train_mape_scorer                  -10.093 (+/- 0.095)  -7.712 (+/- 0.066)   \n",
       "\n",
       "                                            OneVsRest       Random Forest  \\\n",
       "fit_time                            0.100 (+/- 0.006)   1.501 (+/- 0.023)   \n",
       "score_time                          0.006 (+/- 0.000)   0.021 (+/- 0.000)   \n",
       "test_neg_mean_squared_error        -0.648 (+/- 0.006)  -0.395 (+/- 0.027)   \n",
       "train_neg_mean_squared_error       -0.642 (+/- 0.005)  -0.056 (+/- 0.002)   \n",
       "test_neg_root_mean_squared_error   -0.805 (+/- 0.004)  -0.628 (+/- 0.021)   \n",
       "train_neg_root_mean_squared_error  -0.801 (+/- 0.003)  -0.237 (+/- 0.003)   \n",
       "test_neg_mean_absolute_error       -0.520 (+/- 0.003)  -0.450 (+/- 0.012)   \n",
       "train_neg_mean_absolute_error      -0.514 (+/- 0.002)  -0.169 (+/- 0.002)   \n",
       "test_r2                             0.150 (+/- 0.006)   0.482 (+/- 0.027)   \n",
       "train_r2                            0.158 (+/- 0.008)   0.926 (+/- 0.002)   \n",
       "test_mape_scorer                   -9.027 (+/- 0.057)  -8.122 (+/- 0.406)   \n",
       "train_mape_scorer                  -8.917 (+/- 0.035)  -3.041 (+/- 0.049)   \n",
       "\n",
       "                                    Random Forest_rfe  \n",
       "fit_time                            5.762 (+/- 0.081)  \n",
       "score_time                          0.021 (+/- 0.000)  \n",
       "test_neg_mean_squared_error        -0.395 (+/- 0.031)  \n",
       "train_neg_mean_squared_error       -0.056 (+/- 0.002)  \n",
       "test_neg_root_mean_squared_error   -0.628 (+/- 0.025)  \n",
       "train_neg_root_mean_squared_error  -0.238 (+/- 0.003)  \n",
       "test_neg_mean_absolute_error       -0.451 (+/- 0.015)  \n",
       "train_neg_mean_absolute_error      -0.169 (+/- 0.002)  \n",
       "test_r2                             0.481 (+/- 0.032)  \n",
       "train_r2                            0.926 (+/- 0.002)  \n",
       "test_mape_scorer                   -8.125 (+/- 0.447)  \n",
       "train_mape_scorer                  -3.048 (+/- 0.044)  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "cbe8c2ed-b53f-4710-8fc7-746b3e12870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf_rfe.fit(X_train, y_train)\n",
    "pipe_rf_rfe.named_steps['rfe'].ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cb7b5f81-74c5-4793-93b8-9fe504bcaea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_fs = pipe_rf_rfe.named_steps[\"rfe\"].support_\n",
    "rfe_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6aab20c2-fd6e-4033-a8b1-a8a3542e7476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['volatile acidity', 'citric acid', 'residual sugar', 'chlorides',\n",
       "       'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH',\n",
       "       'sulphates', 'alcohol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_selected_feats = X_train.columns[rfe_fs]\n",
    "rfe_selected_feats"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccc79d99-faa3-403e-8eda-d6874b185625",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16b36144-6af4-4e6b-927d-7cd8d5b6c410",
   "metadata": {},
   "source": [
    "By using Recursive Feature Elimination algorithm, we chose to drop \"type\" and \"fixed acidity\" features. Because by dropping those two features, even though we did not get better scores, we are able to achieve the same scores with lesser features. It is great because it will simply our model and save cost for future data collection. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "15d0cad3-6106-4bbb-87d1-730537e69fa7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d5fe175e-979f-4932-93fc-a3e942e65dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "779abf58-612c-46e0-a7ec-5cc4a432784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                               Pipeline(steps=[('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['fixed '\n",
       "                                                                                'acidity',\n",
       "                                                                                'volatile '\n",
       "                                                                                'acidity',\n",
       "                                                                                'citric '\n",
       "                                                                                'acid',\n",
       "                                                                                'residual '\n",
       "                                                                                'sugar',\n",
       "                                                                                'chlorides',\n",
       "                                                                                'free '\n",
       "                                                                                'sulfur '\n",
       "                                                                                'dioxide',\n",
       "                                                                                'total '\n",
       "                                                                                'sulfur '\n",
       "                                                                                'dioxide',\n",
       "                                                                                'density',\n",
       "                                                                                'pH',\n",
       "                                                                                'sulphates',\n",
       "                                                                                'alcohol']),\n",
       "                                                                              ('pipeli...\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'randomforestregressor__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x18ab8df30>,\n",
       "                                        'randomforestregressor__max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x18ab8f7c0>,\n",
       "                                        'randomforestregressor__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x18ab8ee90>},\n",
       "                   random_state=123)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\"randomforestregressor__max_depth\": randint(low=5, high=1000),\n",
    "             \"randomforestregressor__max_leaf_nodes\": randint(low=5, high=1000),\n",
    "             \"randomforestregressor__n_estimators\": randint(low=5, high=1000),}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipe_rf_rfe,\n",
    "    param_distributions=param_dist,\n",
    "    n_jobs=-1,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "45a838e1-2783-42ba-a4c5-eae87901d26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'randomforestregressor__max_depth': 344,\n",
       " 'randomforestregressor__max_leaf_nodes': 851,\n",
       " 'randomforestregressor__n_estimators': 258}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "430b5140-9453-436c-8b97-29a00767afd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48263333317966534"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6143d201-a408-4537-a790-b9fca63e35d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913462954551246"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d0f258a0-0e1c-4269-b09e-2a0f86dc93af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5322298294597634"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6fe02e8-4a82-40cf-a157-ed5e87b9b3fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33820343-78bb-4332-9a62-7d297b44cdf3",
   "metadata": {},
   "source": [
    "Finally, we conduct hyper-parameter optimization. We employed random search to look for same key hyper-parameters, such as max_depth, max_leaf_nodes, and n_estimators. The best hyper-parameter value we got from the algorithm are ['max_depth': 344, 'max_leaf_nodes': 851, 'n_estimators': 258]. And the best validation score we got is 0.48. And the test score is 0.52 after tunning the hyper-parameters. However, as we discovered above, the train score is 0.91, which means we still have overfitting issue by using Random Forest model. We may investigate further and figure out the next steps later. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c32186f3-ac63-4979-ba9d-fd9cd477072a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wine]",
   "language": "python",
   "name": "conda-env-wine-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
